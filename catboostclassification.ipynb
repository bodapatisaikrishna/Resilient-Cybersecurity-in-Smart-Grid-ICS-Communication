{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a6a19-17d5-444f-919f-d22d2584fb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "\n",
    "# Debugging function to check shape alignment\n",
    "def debug_shape(df, name=\"DataFrame\"):\n",
    "    print(f\"{name} shape: {df.shape}\")\n",
    "\n",
    "# Function to safely load CSV files\n",
    "def safe_load_csv(filepath):\n",
    "    try:\n",
    "        return pd.read_csv(filepath, delimiter=';', encoding='utf-8')\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error loading {filepath}. Attempting to skip problematic rows...\")\n",
    "        return pd.read_csv(filepath, on_bad_lines='skip', delimiter=';', encoding='utf-8')\n",
    "\n",
    "# 1. Load datasets\n",
    "normal = safe_load_csv(r\"C:\\Users\\nagas\\OneDrive\\Desktop\\eocs\\ics-dataset-for-smart-grids\\but-iec104-i\\normal-traffic.csv\")\n",
    "switching_attack = safe_load_csv(r\"C:\\Users\\nagas\\OneDrive\\Desktop\\eocs\\ics-dataset-for-smart-grids\\but-iec104-i\\switching-attack.csv\")\n",
    "\n",
    "# 2. Assign labels\n",
    "normal['label'] = 0\n",
    "switching_attack['label'] = 1\n",
    "\n",
    "# Combine all data\n",
    "data = pd.concat([normal, switching_attack], ignore_index=True)\n",
    "debug_shape(data, \"Combined Data\")\n",
    "\n",
    "# Check for mixed or improperly parsed columns and clean\n",
    "def clean_data_columns(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "data = clean_data_columns(data)\n",
    "\n",
    "# 3. Apply a stronger transformation to normal data\n",
    "def transform_normal_data(data, noise_level=0.5):\n",
    "    noise = np.random.normal(0, noise_level, data.shape)\n",
    "    scaled_data = data * np.random.uniform(0.5, 1.5, data.shape)\n",
    "    transformed_data = scaled_data + noise\n",
    "    return transformed_data\n",
    "\n",
    "normal_features = data[data['label'] == 0].drop(columns=['label'])\n",
    "debug_shape(normal_features, \"Normal Features Before Transformation\")\n",
    "\n",
    "# Apply transformation to normal data\n",
    "transformed_normal_features = transform_normal_data(normal_features.to_numpy(), noise_level=0.5)\n",
    "transformed_normal = pd.DataFrame(transformed_normal_features, columns=normal_features.columns)  # Ensure column names match\n",
    "transformed_normal['label'] = 0  # Add label back to match original structure\n",
    "debug_shape(transformed_normal, \"Transformed Normal Data\")\n",
    "\n",
    "# Combine transformed normal data back with attack class\n",
    "attack_data = data[data['label'] == 1]\n",
    "data_transformed = pd.concat([transformed_normal, attack_data], ignore_index=True)\n",
    "debug_shape(data_transformed, \"Data Transformed After Transformation\")\n",
    "\n",
    "# Ensure consistency in data cleaning\n",
    "data_transformed = clean_data_columns(data_transformed)\n",
    "\n",
    "# 4. Handle missing values\n",
    "non_nan_columns = data_transformed.columns[data_transformed.notna().any()].tolist()\n",
    "data_transformed = data_transformed[non_nan_columns]\n",
    "debug_shape(data_transformed, \"Data Transformed After Dropping NaN Columns\")\n",
    "\n",
    "# Separate features and labels\n",
    "features_transformed = data_transformed.drop(columns=['label'])\n",
    "label_transformed = data_transformed['label']\n",
    "debug_shape(features_transformed, \"Features Transformed\")\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "features_cleaned = imputer.fit_transform(features_transformed)\n",
    "\n",
    "# Ensure column alignment\n",
    "features_cleaned_df = pd.DataFrame(features_cleaned, columns=features_transformed.columns)\n",
    "features_cleaned_df['label'] = label_transformed.reset_index(drop=True)\n",
    "debug_shape(features_cleaned_df, \"Features Cleaned\")\n",
    "\n",
    "# 5. Feature selection and preprocessing\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_features = [col for col in features_cleaned_df.columns if col != 'label']\n",
    "features_cleaned_df[numerical_features] = scaler.fit_transform(features_cleaned_df[numerical_features])\n",
    "features_cleaned_df['label'] = features_cleaned_df['label'].astype(int)\n",
    "\n",
    "# Ensure no NaN or inf values in normal_features and transformed_normal_features\n",
    "normal_features_clean = np.nan_to_num(normal_features.to_numpy(), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "transformed_normal_features_clean = np.nan_to_num(transformed_normal_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "euclidean_distances = [euclidean(original, transformed) \n",
    "                       for original, transformed in zip(normal_features_clean, transformed_normal_features_clean)]\n",
    "\n",
    "euclidean_mean = np.mean(euclidean_distances)\n",
    "euclidean_std = np.std(euclidean_distances)\n",
    "\n",
    "print(f\"Euclidean Distance: Mean = {euclidean_mean}, Std Dev = {euclidean_std}\")\n",
    "\n",
    "# Plot Euclidean Distance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(euclidean_distances, kde=True, bins=50, color='green', label='Euclidean Distance')\n",
    "plt.title('Euclidean Distance Before and After Transformation', fontsize=16)\n",
    "plt.xlabel('Euclidean Distance', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 6. Split data\n",
    "X = features_cleaned_df.drop(columns=['label'])\n",
    "y = features_cleaned_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "debug_shape(X_train, \"X_train\")\n",
    "debug_shape(X_test, \"X_test\")\n",
    "\n",
    "# Check class distribution before resampling\n",
    "print(\"Class distribution in y_train:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# 7. Handle imbalance using SMOTE\n",
    "# Ensure we are oversampling the minority class to at least match the majority class count\n",
    "majority_class_count = y_train.value_counts().max()\n",
    "smote = SMOTE(sampling_strategy={1: majority_class_count}, random_state=42)  # Oversample minority to match majority\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "debug_shape(X_train_resampled, \"X_train_resampled\")\n",
    "\n",
    "# Check class distribution after resampling\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(y_train_resampled.value_counts())\n",
    "\n",
    "# 8. Train classifier - Using CatBoost instead\n",
    "clf = CatBoostClassifier(random_state=42, verbose=0)  # verbose=0 to suppress output\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 9. Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate ROC Curve\n",
    "y_pred_prob = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('True', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Metrics Plot\n",
    "metrics_df = pd.DataFrame(report).transpose().iloc[:-1, :3]\n",
    "metrics_df.plot(kind='bar', figsize=(12, 6), color=['blue', 'green', 'red'])\n",
    "plt.title('Classification Metrics', fontsize=16)\n",
    "plt.xlabel('Metrics', fontsize=14)\n",
    "plt.ylabel('Score', fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
